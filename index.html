<html>
<head>
<title>Arman Afrasiyabi homepage</title>
</head>
<STYLE>
<!--
A{text-decoration:none}
-->
</STYLE>


<BODY MARGINWIDTH=0 MARGINHEIGHT=0 BGCOLOR="#FFFFFF" TEXT="#000000" LINK="#0000C8" ALINK="#C80000"> 
<table border="0" cellpadding="15" cellspacing="0" width="1000">
<td class="sidebar">&nbsp;</td>
</tr>
<tr>

<td class="sidebar" valign="top">
<table border=0 cellspacing=0 cellpadding=2>
&nbsp;&nbsp;&nbsp;&nbsp;
</table>
</td>

<td valign="top">

<p>
<table border="0" cellpadding="0" cellspacing="0" width="98%">
<td align="left" width="78%">
<font face="helvetica, ariel, 'sans serif'" size="3"> 
    <font size="+2">
    <b>Arman Afrasiyabi</b><br></font>
</font>
<font face="helvetica, ariel, 'sans serif'">
    PhD candidate, <br /> <a href="https://iid.ulaval.ca">IID,</a> <a href="https://www.gelgif.ulaval.ca/accueil/"> EECE Department, <a href="https://www.ulaval.ca/">Université Laval


</a> <br />
    <!--<a href="https://www.ulaval.ca/en">Université Laval</a></br>
    Address: LVSN, Québec, QC G1V 0A6, Canada<br>
    Email: arman.afrasiyabi@gmail/dot/com<br> -->
   <p>

<p>
<p>
I am a PhD candidate at <a href="https://iid.ulaval.ca">Institute Intelligence and Data (IID)</a> of <a href="https://www.ulaval.ca/">Université Laval</a>, 
supervised by <a href="http://vision.gel.ulaval.ca/~jflalonde/">Jean-François Lalonde</a> and <a href="http://vision.gel.ulaval.ca/~cgagne/english.html"> Christian Gagné</a>. 
My research is based on the investigation of machine learning and deep learning in the context of computer vision. 
I am working on meta-learning and representation learning in the low supervision regimes.
<!--After completing my master on brain decoding and energy saving challanges at <a href="https://metu.edu.tr/"> METU</a>, where I completed my master under the supervision of <a href="https://scholar.google.co.uk/citations?user=zPFQ2BwAAAAJ&hl=en"> Fatos T. Yarman Vural</a>.-->   

<p>
 
Up to now, with my supervisors, we presented the idea of associative alignment <a href="https://lvsn.github.io/associative-alignment/"> (eccv-2020) </a> 
to increase the learning capacity, also we proposed persistent mixture model <a href="https://arxiv.org/abs/2011.11872"> (arxiv-under review)</a> 
as a representation learning approach to gain adaptivity in few-shot classification problem.   
Now, we are investigating a novel approach under self-supervised context to leave out the labeling cost in the base domain in the meta-learning approaches. 
 
<p>
<p>
For more details, see the <b> <a href="https://armanafrasiyabi.github.io/files/arman_cv.pdf"> CV</b></a> and <b><a href="https://scholar.google.com/citations?user=eLmbCr8AAAAJ&hl=en">Google Scholar</a></b>.  
 
<p>
<p>
    <p>
    <p>
</font>
    </td>
	<td width="184.4" height="251.6">
	<img src="./files/arman_bw.jpg" width="184.4" height="251.6">
	</td>
	</tr>
</table>

	
<font face="helvetica, ariel, 'sans serif'">
<p>

<!--<hr size="1" align="left" noshade>
<h2> 
<p>
</p>
		<p align="center">
		    <a href="#publications">Publications</a> |
		    <a href="./files/arman_cv.pdf"> CV </a> |
		    <a href="https://scholar.google.com/citations?user=eLmbCr8AAAAJ&hl=en">Scholar</a> | 
		    <a href="https://www.linkedin.com/in/arman-afrasiyabi-40b48810b/?originalSubdomain=ca"> LinkedIn </a> 
		</p>

-->
</h2>
<p>
<hr size="1" align="left" noshade>
<p>

 
<h2>News and updates</h2>

<div class="home"><h1 class="page-heading">
</h1>
	    <ul>
	      <li> New paper on arxiv: <a href="https://arxiv.org/pdf/2011.11872.pdf"> Persistent Mixture Model Networks for Few-shot Image Classification</a></a></a>!</li>
	      <li> Our paper “<a href="https://lvsn.github.io/associative-alignment/">Associative Alignment for Few-shot Image Classification</a>” got accepted as a <b> spotlight </b>  (5% acceptance rate) at <a href="https://eccv2020.eu"><b>ECCV2020</b></a></a>!</li>
	      <li> Our abstract is acceptanced at <a href="http://montrealaisymposium.com/">Montreal AI Symposium (MAIS) 2020</a></a></a>!</li>
              <li> I got accepted and attending to <a href="https://dlrl.ca/">CIFAR Deep Learning + Reinforcement Learning Summer School 2020</a></a></a>!</li>
              <li> In January 2019, I successfully passed my PhD retrospective and prospective evaluations: </a> <a href="./pdfs/2019,01,16 Only_Presentation for PhDProposal (Arman Afrasiyabi).pdf">[presentation] </a> and <a href="https://github.com/ArmanAfrasiyabi/talks-presentations-repots/blob/master/retrospective%20and%20prospective%20evaluations/Reducing%20the%20need%20for%20large%20labeleddataset%20in%20the%20learning%20to%20learn%20framework.pdf">[proposal]
</a>.</li>
              <li> Our paper “<a href="http://repository.bilkent.edu.tr/bitstream/handle/11693/50181/Bilkent-research-paper.pdf?sequence=1">Non-Euclidean Vector Product for Neural Networks</a>” got accepted at <a href="https://2018.ieeeicassp.org/Default.asp">ICASSP 2018</a></a>.</li>
</div>





<h2>Talks and presentations</h2>
<div class="home"><h1 class="page-heading">
</h1>
<ul>
        
                <li> At ECCV 2020, I prepared a spotlight presentation on our last work “Associative Alignment for Few-shot Image Classification”. <a href="https://lvsn.github.io/associative-alignment/">[the video]</a></li>
		<li> In July 2020, I gave a talk on ”Advances in few-shot learning”</a> at Université Laval, IFT 6501. 
<a href="./pdfs/26-6-2020 advances in few-shot learning .pdf"> [my slides]</a></a></li>  

		<li> In March 2020, I gave a talk on my last reasearch project at <a href="https://iid.hbw01.fsg.ulaval.ca/evenements/seminaire-iid-associative-alignment-for-few-shot-image-classification/">Intelligence and Data Institute (IID)</a>,  Université Laval. <a href="./pdfs/Associative Alignmentfor Few-Shot Image Classification.pdf">[my slides]</a></a></li>

 
            	 
                <li> In January 2018, I gave a presentation on  ”Neural Turing Machines: RNN, NTM and DNC”. 
			<a href="./pdfs/2018, 26, Jan Presentation (Arman Afrasiyabi) LabComputer.pdf"> [my slides-NTM]</a>
                        <a href="./pdfs/Arman_Afrasiyabi_Presentation_RNNs.pdf"> [my slides-RNN]</a></a></li>
  </div>






<h2>Publications</h2>

See my <a href="https://scholar.google.com/citations?user=eLmbCr8AAAAJ&hl=en">google scholar</a> for complete list of the publications.
<br>

<font face="helvetica, ariel, 'sans serif'">
<table cellspacing="15"> 
<tr>
<td width="35%">
<a 
href="https://arxiv.org/pdf/2011.11872.pdf">
<img src="./files/vizualizationPMM.PNG"
height="200" width="340"
border="0"></a>
</td>
<td>
<a 
href="https://arxiv.org/pdf/2011.11872.pdf">
<b>Persistent Mixture Model Networks for Few-Shot Image Classification.</b></a>
<strong>Arman Afrasiyabi</strong>
<a href="http://vision.gel.ulaval.ca/~jflalonde/">Jean-François Lalonde</a>, <a href="http://vision.gel.ulaval.ca/~cgagne/">Christian Gagné</a>, arXiv:2011.11872v1, this work is <strong>under review</strong>.
<br>
<br>
We introduce Persistent Mixture Model (PMM) networks for representation learning in the few-shot image classification context. While previous methods represent classes with a single centroid or rely on post hoc clustering methods, our method learns a mixture model for each base class jointly with the data representation in an end-to-end manner. </a>
</td>














<font face="helvetica, ariel, 'sans serif'">
<table cellspacing="15"> 
<tr>
<td width="35%">
<a 
href="https://lvsn.github.io/associative-alignment/">
<img src="./files/assotiative_alignment.PNG"
height="200" width="340"
border="0"></a>
</td>
<td>
<a 
href="https://lvsn.github.io/associative-alignment/">
<b>Associative Alignment for Few-shot Image Classification.</b></a>
<br>
<strong>Arman Afrasiyabi</strong>,
<a href="http://vision.gel.ulaval.ca/~jflalonde/">Jean-François Lalonde</a>,
<a href="http://vision.gel.ulaval.ca/~cgagne/">Christian Gagné</a>,
in European Conference on Computer Vision <b>(ECCV)</b> 2020 as a <strong>spotlight</strong> presentation.
<br>
<br>
We propose the idea of associative alignment for leveraging part of the base data by aligning the novel training instances to the closely related ones in the base training set. This expands the size of the effective novel training set by adding extra "related base" instances to the few novel ones.
<a href="https://lvsn.github.io/associative-alignment/"></h1> <strong>[10 min video]</strong></h1></a>
</td>






<font face="helvetica, ariel, 'sans serif'">
<table cellspacing="15"> 
<tr>
<td width="35%">

<a 
href="https://par.nsf.gov/servlets/purl/10067379">
<img src="./files/ICCASP18.png"
height="200" width="340"
border="0"></a>
</td>
<td>
<a 
href="https://par.nsf.gov/servlets/purl/10067379">
<b>Non-Euclidean Vector Product for Neural Networks.</b></a>
<br>
<strong>Arman Afrasiyabi</strong>,
<a href="https://scholar.google.com/citations?user=yQPCimQAAAAJ&hl=en">Diaa Badawi</a>,
<a href="http://user.ceng.metu.edu.tr/~bnasir/">Baris Nasir</a>,
Ozan Yildiz,
<a href="https://scholar.google.co.uk/citations?user=zPFQ2BwAAAAJ&hl=en">Fatos T. Yarman Vural</a>,
<a href="https://scholar.google.com/citations?user=apugsswAAAAJ&hl=en">A Enis Çetin</a>,
in International Conference on Acoustics, Speech and Signal Processing <b>(ICASSP)</b> 2018.
<br>
<br>
We present a non-Euclidean vector product for artificial neural networks. The vector product operator does not require any multiplications while providing correlation information between two vectors, unlike ordinary neurons which require inner product of two vectors.</h1></a>
</td>



 





<font face="helvetica, ariel, 'sans serif'">
<table cellspacing="15"> 
<tr>
<td width="35%">

<a 
href="https://www.researchgate.net/publication/313963281_A_Sparse_Temporal_Mesh_Model_for_brain_decoding">
<img src="./files/STMM16.png"
height="195" width="335"
border="0"></a>
</td>
<td>
<a 
href="https://ieeexplore.ieee.org/abstract/document/7862035">
<b>A sparse temporal mesh model for brain decoding.</b></a>
<br>
<strong>Arman Afrasiyabi</strong>,
<a href="https://itironal.github.io/">Itır Önal Ertuğrul</a>,
<a href="https://scholar.google.co.uk/citations?user=zPFQ2BwAAAAJ&hl=en">Fatos T. Yarman Vural</a>
in the 15th International Conference on Cognitive Informatics & Cognitive Computing <b>(ICCI*CC)</b> 2016 hosted by Stanford University.
<br>
<br>
We propose a new architecture, called Sparse Temporal Mesh Model (STMM), which reduces the dimension of the feature space by combining the voxel selection methods with the mesh learning method. 
We, first, select the “most discriminative” voxels using the state-of-the-art feature selection methods. </h1></a>
</td>





<font face="helvetica, ariel, 'sans serif'">
<table cellspacing="15"> 
<tr>
<td width="35%">

<p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p>

</h2>
<p>
<hr size="1" align="left" noshade>
<p>
The design of this page is inspired from professor <a href="https://people.eecs.berkeley.edu/~efros/"> Alexei (Alyosha) Efros</a>'s homepage.
